{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d03d621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8423f233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1750000, 23) [ 2.  2.  2. ... 17. 17. 17.]\n"
     ]
    }
   ],
   "source": [
    "all_data = pickle.load(open(\"all_14sub/all_14sub.p\", \"rb\" ),encoding='iso-8859-1')\n",
    "print(type(all_data), all_data.shape, all_data[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "189fbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2312c5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(y_):\n",
    "    # Function to encode output labels from number indexes\n",
    "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
    "    y_ = y_.reshape(len(y_))\n",
    "    y_ = [int(x) for x in y_]\n",
    "    n_values = np.max(y_) + 1\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22948f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(input, n_fea, time_window, moving):\n",
    "    global n_classes\n",
    "    xx = input[:, :n_fea]\n",
    "    yy = input[:, n_fea:n_fea + 1]\n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    number = int((xx.shape[0] / moving) - 1)\n",
    "    for i in range(number):\n",
    "        ave_y = np.average(yy[int(i * moving):int(i * moving + time_window)])\n",
    "        if ave_y in range(n_classes + 1):\n",
    "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
    "            new_y.append(ave_y)\n",
    "        else:\n",
    "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
    "            new_y.append(0)\n",
    "\n",
    "    new_x = np.array(new_x)\n",
    "    new_x = new_x.reshape([-1, n_fea * time_window])\n",
    "    new_y = np.array(new_y)\n",
    "    new_y.shape = [new_y.shape[0], 1]\n",
    "    data = np.hstack((new_x, new_y))\n",
    "    data = np.vstack((data, data[-1]))  # add the last sample again, to make the sample number round\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31ab545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_t(v_xs, v_ys):  # this function only calculate the acc of CNN_task\n",
    "    global prediction_t\n",
    "    y_pre = sess.run(prediction_t, feed_dict={xs: v_xs, keep_prob: keep})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys_t: v_ys, keep_prob: keep})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8767bcff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_p(v_xs, v_ys):  # this function only calculate the acc of CNN_task\n",
    "    global prediction_p\n",
    "    y_pre = sess.run(prediction_p, feed_dict={xs: v_xs, keep_prob: keep})\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pre,1), tf.argmax(v_ys,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    result = sess.run(accuracy, feed_dict={xs: v_xs, ys_p: v_ys, keep_prob: keep})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f24b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1750000, 23) [ 2.  2.  2. ... 17. 17. 17.]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "n_person_ = 13  # the number of training subjects\n",
    "sample_persub = 250*500  # we have overlapping now\n",
    "print(type(all_data), all_data.shape, all_data[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75895eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of maked person label (13000, 1)\n"
     ]
    }
   ],
   "source": [
    "no_fea = 21  # data.shape[-1] - 1\n",
    "seg_length = 250  # # 255 for raw data, 96 for layer 23, 64 for layer 2, 32 for layer 2\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()  # normalization\n",
    "F = scaler.fit_transform(all_data[:, :no_fea])  # scale to [0, 1]\n",
    "\n",
    "all_data = np.hstack((F, all_data[:, no_fea:no_fea+1]))  # only use the task ID\n",
    "\n",
    "\n",
    "\"\"\"Make person label\"\"\"\n",
    "n_sample_ = int(2*sample_persub/seg_length )  # the number of sampls of each subject after reshape\n",
    "ll = np.ones([n_sample_, 1])*0\n",
    "for hh in range(1, n_person_):\n",
    "    ll_new = np.ones([n_sample_, 1])*hh\n",
    "    ll = np.vstack((ll, ll_new))\n",
    "print('the shape of maked person label', ll.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab997139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7aa1b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (1750000, 22) [0. 0. 0. ... 1. 1. 1.]\n",
      "the shape of maked person label (13000, 1)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 2\n",
    "n_person_ = 13  # the number of training subjects\n",
    "sample_persub = 250*500  # we have overlapping now\n",
    "print(type(all_data), all_data.shape, all_data[:, -1])\n",
    "\n",
    "no_fea = 21  # data.shape[-1] - 1\n",
    "seg_length = 250  # # 255 for raw data, 96 for layer 23, 64 for layer 2, 32 for layer 2\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()  # normalization\n",
    "F = scaler.fit_transform(all_data[:, :no_fea])  # scale to [0, 1]\n",
    "\n",
    "all_data = np.hstack((F, all_data[:, no_fea:no_fea+1]))  # only use the task ID\n",
    "\n",
    "\n",
    "\"\"\"Make person label\"\"\"\n",
    "n_sample_ = int(2*sample_persub/seg_length )  # the number of sampls of each subject after reshape\n",
    "ll = np.ones([n_sample_, 1])*0\n",
    "for hh in range(1, n_person_):\n",
    "    ll_new = np.ones([n_sample_, 1])*hh\n",
    "    ll = np.vstack((ll, ll_new))\n",
    "print('the shape of maked person label', ll.shape)\n",
    "\n",
    "ll_test = np.ones([n_sample_, 1])*n_person_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dbe674b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2e1dfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.637354921797418\n",
      "0.4338924404170804\n",
      "0.6519403239821252\n",
      "0.9156229166666667\n",
      "0.5600666666666667\n",
      "0.6715666666666666\n",
      "0.9871580242673993\n",
      "0.44442536630036633\n",
      "0.7479073660714286\n",
      "0.8733030174471019\n",
      "0.47268476781389757\n",
      "0.5874144879885453\n",
      "0.5567462422634837\n",
      "0.5958974358974358\n",
      "0.48318302387267903\n",
      "0.9021625000000001\n",
      "0.45823749999999996\n",
      "0.5449208333333333\n",
      "0.7784925312980175\n",
      "0.4696151036550039\n",
      "0.6544434368623895\n",
      "0.7335393101522134\n",
      "0.5552646278452731\n",
      "0.6253534771679933\n",
      "0.5934665723778736\n",
      "0.5189194953304598\n",
      "0.4804743624281609\n",
      "0.8543\n",
      "0.4917416666666667\n",
      "0.5912125\n",
      "0.9160314479304759\n",
      "0.5612019443216968\n",
      "0.7390862056267491\n",
      "0.6630083333333334\n",
      "0.5148333333333334\n",
      "0.6041583333333334\n",
      "0.7438881802721088\n",
      "0.43773030045351474\n",
      "0.5652695105820105\n",
      "0.7041029299093815\n",
      "0.5730429843333069\n",
      "0.5151085836569708\n"
     ]
    }
   ],
   "source": [
    "rf_auc_list = []\n",
    "svm_auc_list = []\n",
    "knn_auc_list = []\n",
    "for P_ID in range(14):  # n_person_++1\n",
    "    if P_ID==0:\n",
    "        reuse=False\n",
    "    else:\n",
    "        reuse=True\n",
    "    \"\"\"Select train and test subject\"\"\"\n",
    "    data_ = all_data[sample_persub*P_ID:sample_persub*(P_ID+1)]\n",
    "\n",
    "    list = range(sample_persub*P_ID, sample_persub*(P_ID+1))\n",
    "    data = np.delete(all_data, list, axis=0)\n",
    "    # overlap\n",
    "    train_data = extract(data, n_fea=no_fea, time_window=seg_length, moving=(seg_length/2))\n",
    "    test_data = extract(data_, n_fea=no_fea, time_window=seg_length, moving=(seg_length/2))  # 50% overlapping\n",
    "    # continue\n",
    "    \"\"\"Replace the original person data by the maked data\"\"\"\n",
    "    no_fea_long = train_data.shape[-1] - 1  # here is - 2, because has two IDs\n",
    "\n",
    "    train_data = np.hstack((train_data[:, :no_fea_long+1], ll))\n",
    "    test_data = np.hstack((test_data[:, :no_fea_long + 1], ll_test))\n",
    "\n",
    "    np.random.shuffle(train_data)\n",
    "    np.random.shuffle(test_data)\n",
    "\n",
    "\n",
    "    feature_train = train_data[:, :no_fea_long]\n",
    "    feature_test = test_data[:, :no_fea_long]\n",
    "    label_train_t = train_data[:, no_fea_long:no_fea_long + 1]\n",
    "    label_test_t = test_data[:, no_fea_long:no_fea_long + 1]\n",
    "    label_train_p = train_data[:, no_fea_long + 1:no_fea_long + 2]\n",
    "\n",
    "    label_train_t = one_hot(label_train_t)\n",
    "    label_test_t = one_hot(label_test_t)\n",
    "    label_train_p = one_hot(label_train_p)\n",
    "    \n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=50)\n",
    "    labels = label_train_t[:,0]\n",
    "    rf.fit(feature_train,labels)\n",
    "\n",
    "    preds = rf.predict_proba(feature_test)\n",
    "    preds = preds[:,1]\n",
    "    preds = [*preds]\n",
    "    \n",
    "    print(metrics.roc_auc_score(label_test_t[:,0],preds))\n",
    "    rf_auc_list.append((metrics.roc_auc_score(label_test_t[:,0],preds)))\n",
    "    \n",
    "    svm_model = svm.SVC(C = 1.0, kernel = 'linear', probability = True)\n",
    "    svm_model.fit(feature_train, labels)\n",
    "    \n",
    "    preds = svm_model.predict_proba(feature_test)\n",
    "    preds = preds[:,1]\n",
    "    preds = [*preds]\n",
    "    \n",
    "    print(metrics.roc_auc_score(label_test_t[:,0],preds))\n",
    "    svm_auc_list.append((metrics.roc_auc_score(label_test_t[:,0],preds)))\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    knn.fit(feature_train, labels)\n",
    "    \n",
    "    preds = knn.predict_proba(feature_test)\n",
    "    \n",
    "    preds = preds[:,1]\n",
    "    preds = [*preds]\n",
    "    \n",
    "    print(metrics.roc_auc_score(label_test_t[:,0],preds))\n",
    "    knn_auc_list.append((metrics.roc_auc_score(label_test_t[:,0],preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1114b560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7756554948368196\n",
      "0.5062538309310503\n",
      "0.6044313651123133\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(rf_auc_list))\n",
    "print(np.mean(svm_auc_list))\n",
    "print(np.mean(knn_auc_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
